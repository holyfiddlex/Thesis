\documentclass{book}

\usepackage{blindtext}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[left=4cm, right=4cm, top=3cm]{geometry}

\setlength{\parindent}{2em}
\setlength{\parskip}{1em}

\begin{document}

\chapter{The Cocktail Party Problem}
\qquad Speech separation has been a problem that researchers have been interested in for years. So much so that the problem was formulated decades ago by Colin Cherry\cite{Cherry}. In his famous paper he gives an example of the task with a conversation in a Cocktail party, giving the problem its name. Over 65 years later one could argue that progress is just now being made in the area, mostly due to the advancements in general learning algorithms, like deep learning, giving an edge in unstructured data analysis.
\par
Many studies*** have been used to divide the problem into more manageable tasks, many of which were included in the experiments made by Cherry himself. Thanks to this, the problem has evolved quite a bit since it was first formulated, deviating from its original definition and including all types of noise, not just speech. As McDermott mentions in his article\cite{CocktailPartyProblemRevisit}, the problem has been split in two parts, which together engulfs the problem as a whole. Usually both parts are frequently referred to as the Cocktail Party problem interchangeably.
\par
The first part addresses who or what to pay attention to, and when to change targets. For clarity in this paper, we will refer to this specific part as the Attention problem. To solve this problem we need background knowledge about the person paying attention as well as the context to know what the listener wants to listen to. What's more is that the listener might want to listen to two speakers at the same time, given that they are both saying something important. The difficulty of the problem lies in how subjective it is. Because of this, it is practically impossible to model and automate the process.
\par
The second part refers to actually separating the sounds, or also known as “sound segregation”. This part will be referred to as the “segregation problem. This differs from the previous task because here we look to separate the audio by different sources. We have no need to know which is more important than the other, as long as we can listen to each source independently. This is the process that has received more attention in the last couple of years, since it is easier to model. That said, it is still an ill-posed problem (more on this later) which means that traditional methods have a hard time.
\par
In this thesis we will only be addressing the segregation problem, trying to separate an audio by the different sources of noise it contains. This problem has quite a bit of research *** but still has a long way before we can actually consider it to be solved. One of the reasons was just mentioned, but it’s also due to the fact that the problem, under certain conditions, becomes impossible to model. This leaves us with a few options, we either limit the problem to certain use cases, or we facilitate the problem adding more information. We will consider both of these actions to be “constraints”, as one limits the conditions that could be solved while the other limits possible solutions, requiring more information.

\section{Inverse Problems}

\qquad An inverse problem refers to reconstructing the source from a generated set of components. In this case, we want to reconstruct the separated audios from a generated mixed audio. Inverse problems are usually classified by how “Well-Posed” it is, which is also generally used as an indicator of how difficult the problem could be. Many examples of Inverse problems that extend to signal processing include medical imaging, oceanography, astronomy and geophysics. [InverseProblems]
\par
An inverse problem has 4 components, this includes a measurement operator (MO), injectivity or regularization of the MO, knowledge on noise and the model and finally a numerical implementation. Some of these components are then separated into different sub-catagories, but we will only mention the ones relevant to this work. We address the components based on Guillaume Bal’s definition [InverseProblems].

\begin{center}
\noindent Measurement Operator
\end{center}
\begin{itemize}
    \item 1
    \item 2
    \item 3
\end{itemize}

\begin{center}
\noindent Injectivity
\end{center}
\begin{itemize}
    \item 1
    \item 2
    \item 3
\end{itemize}

\begin{center}
    \noindent Noise and Model
\end{center}
\begin{itemize}
    \item Noise is practically inevitable in audio, extending from white to brown noise and most times even “structured” noise. This could come from background music or oncoming traffic. When we record in a crowded room the noise changes too, leaving a sound that we can relate with a busy street.

    \item The measurement will also have errors, but these are less relevant to us. In audio compression, there is always a slight error from the original source to what we hear later on. This, however, is such a small change that we as humans cannot perceive it, at least not without the help of special tools.

    \item ***
\end{itemize}
    
Numerical Implementation
    For this project we will be using an optimization method, comparing it to previous linear systems. Although these methods were usually considered fairly inexpensive, we will be using neural networks, which are both expensive computational as well as in the data sense. 


\section{Ill-Posed Problems}

\qquad Let's imagine that we have an audio with two sources that generate noise. One is a dog, and the other is a human. Both audio have different structures and can be separated by a person with quite little effort. We could even separate the audios using certain statistical methods***. Sadly the Cocktail Party includes problems much more complicated than the one we just mentioned. A wide variety of audios include at least two people talking. This is harder to separate, sometimes even for humans, especially if the two individuals have similar voices and speak in a similar manner.
\par
    The difficulty of the Cocktail Party problem is that it is Ill-Posed. The terms Ill and Well-Posed problems was first coined by Hadamard, Jacques, a French mathematician born in the mid 1800’s. According to his definition, a problem is considered to be Well-Posed if: 
\begin{itemize}
    \item For any input there is a solution
    \item That solution is unique
    \item The solution is “stable” in the input space (continuous)
\end{itemize}
    If one of these three conditions were not met, the problem was considered Ill-Posed. At the time, it was considered necessary for any mathematical problem in physics and tech to be formulated as a well-posed problem. This meant that, for practical uses, studying Ill-Posed problems was useless[Ill-Posed].

    Now, however, Ill-Posed problems are very common, in fact it is considered rare that a inverse-problem should be well-posed. It has come to the point where researchers seemingly compare how “Ill-Posed” a problem may be[InverseProblems]. These extends to Well, mildly Ill and severely Ill-Posed problems.

\section{Constraints}

\qquad If we continue with our thought experiment from before, what would happen if instead we had two machines that emit static noise of the same type, same volume similar position etc. This would be practically impossible to separate without knowing more about the noise being emitted to try and find some structural difference in the two. Not only that, but the problem wouldn’t be useful in this broader sense. Why would you want to separate noise from noise? The situations where we want to solve the problem don’t require us to tackle a perfectly generalized version of it. This is why it is common to set constraints to the problem before beginning to train a model.
\par
As mentioned before, this work is about speech separation, so it is fair to assume that the audio will have at least two people talking. Another constraint we will add is that we will only focus on english speakers, leaving a more general model for another project. As we will see below we will also be using the Common Voice dataset. This dataset is publicly available to make similar models and consists of almost 40000 voices in more than 1000 hours of recorded english voice in different accents.
\par
We could also consider the number of speakers as a constraint, since having only 2 speakers simplifies the problem greatly. During these tests*** we will try to make a general model that can split the different speakers even when mixed with an arbitrary amount of voices. Clearly there will be a limit given how 100 voices will more than likely be worse than gibberish, but this arbitrary model could help us separate audio even when unexpected speakers enter the conversation.
\par
Another constraint that could be considered is that we only need to listen to one voice. If you use a hypothetical “perfect” model to separate voices and listen to your friend in a crowded cocktail party, you have little to no interest in listening to other people's conversations. Although this could definitely be easier and give better results, we go back to what we mentioned before when we introduced the cocktail party. This constraint in reality mentions a problem with attention, which for now we are considering a different problem.


\bibliography{The Cocktail Party}
\bibliographystyle{ieeetr}
\end{document}
